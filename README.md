# ğŸ“ˆ Real-Time Crypto Price Tracker using Kafka, Spark & Matplotlib

This project is a real-time data pipeline that tracks and visualizes **Bitcoin (BTC)** prices live.

It uses:
- ğŸ“¨ Kafka for real-time data streaming
- âš¡ PySpark for processing incoming data streams
- ğŸ“ CSV for local storage
- ğŸ“Š Matplotlib for live visualization

---

## ğŸ§  Project Motivation

In modern data systems, the ability to **stream, process, and visualize data in real-time** is critical.  
This project simulates a financial analytics system that fetches live BTC prices, streams them using Kafka, and visualizes them live.

Perfect for:
- Practicing real-time pipelines
- Understanding Kafka + Spark integration
- Building data engineering skills

---

## ğŸ› ï¸ Tech Stack Used

| Component         | Technology                     |
|------------------|--------------------------------|
| Data Source       | [CoinGecko API](https://www.coingecko.com) |
| Messaging Queue   | Apache Kafka (localhost)       |
| Stream Processing | PySpark (Structured Streaming) |
| Storage           | CSV (local filesystem)         |
| Visualization     | Matplotlib (live refresh)      |

---

## ğŸ“¦ Project Structure

```
real-time-crypto-kafka-project/
â”œâ”€â”€ producer/
â”‚   â””â”€â”€ crypto_producer.py
â”œâ”€â”€ consumer/
â”‚   â””â”€â”€ spark_crypto_processor.py
â”œâ”€â”€ visualization/
â”‚   â”œâ”€â”€ visualize.py
â”‚   â””â”€â”€ visualize_live.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ processed_crypto/        # Output CSVs from Spark
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ How to Run the Project

### âœ… Step 1: Start Kafka & Zookeeper (on localhost)

Make sure you have Kafka & Zookeeper running locally. You can use these:

```bash
zookeeper-server-start.bat config/zookeeper.properties
kafka-server-start.bat config/server.properties
```

### âœ… Step 2: Install Python Requirements

```bash
pip install -r requirements.txt
```

### âœ… Step 3: Run the Kafka Producer

```bash
python producer/crypto_producer.py
```

This fetches live BTC price and sends to Kafka topic `crypto_prices`.

### âœ… Step 4: Run the Spark Streaming Consumer

```bash
spark-submit consumer/spark_crypto_processor.py
```

It reads from Kafka, processes the data, and writes to `data/processed_crypto/`.

### âœ… Step 5: Live Visualization (Matplotlib)

```bash
python visualization/visualize_live.py
```

This plots the real-time BTC price from the CSV output.

---

## ğŸ§ª Sample Message (JSON)

```json
{
  "symbol": "BTC",
  "price_usd": 29457.23,
  "timestamp": "2025-08-08T16:10:00Z"
}
```

---

## ğŸ“Š Sample Output (Screenshot)

> *Insert chart image here if available*

---

## ğŸ“ˆ Future Improvements

- Add support for Ethereum (ETH) and other coins
- Write data into PostgreSQL or data lake
- Build Streamlit dashboard for live web UI
- Use Docker for complete orchestration

---

## ğŸ‘¨â€ğŸ’» Author

Made with â¤ï¸ by [Your Name]  
GitHub: https://github.com/yourusername